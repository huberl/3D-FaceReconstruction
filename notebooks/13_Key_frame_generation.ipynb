{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "viral-magnitude",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/marc/local-dev/3D-FaceReconstruction\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "collective-crown",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pyrender\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy import optimize\n",
    "from math import sin, cos\n",
    "from numpy.linalg import det\n",
    "\n",
    "from face_reconstruction.data.biwi import BiwiDataLoader\n",
    "from face_reconstruction.data.iphone import IPhoneDataLoader\n",
    "from face_reconstruction.model import BaselFaceModel\n",
    "from face_reconstruction.landmarks import load_bfm_landmarks, detect_landmarks\n",
    "from face_reconstruction.graphics import draw_pixels_to_image, register_rgb_depth, backproject_points, interpolate_around, SimpleImageRenderer, setup_standard_scene, get_perspective_camera, backproject_image\n",
    "from face_reconstruction.optim import BFMOptimization, run_icp, NearestNeighborMode, DistanceType, nearest_neighbors\n",
    "from face_reconstruction.utils.math import add_column, geometric_median\n",
    "from env import PLOTS_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "skilled-animal",
   "metadata": {},
   "source": [
    "# 1. Face Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "tamil-cemetery",
   "metadata": {},
   "outputs": [],
   "source": [
    "bfm = BaselFaceModel.from_h5(\"model2019_face12.h5\")\n",
    "bfm_landmarks = load_bfm_landmarks(\"model2019_face12_landmarks_v2\")\n",
    "bfm_landmark_indices = np.array(list(bfm_landmarks.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "generous-thread",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_shape_coefficients = bfm.get_n_shape_coefficients()\n",
    "n_expression_coefficients = bfm.get_n_expression_coefficients()\n",
    "n_color_coefficients = bfm.get_n_color_coefficients()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "powerful-affairs",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(frame_id):\n",
    "    loader = IPhoneDataLoader()\n",
    "    frame = loader.get_frame(frame_id)\n",
    "    img = frame.get_color_image()\n",
    "    depth_img = frame.get_depth_image()\n",
    "    img_width = loader.get_image_width()\n",
    "    img_height = loader.get_image_height()\n",
    "    intrinsics = frame.get_intrinsics()\n",
    "    \n",
    "    depth_threshold = 0.5 # Drop all points behind that threshold\n",
    "    \n",
    "    points = backproject_image(intrinsics, depth_img)\n",
    "    points_to_render = points[:, :3]\n",
    "    points_to_render *= 1000 # meter to millimeter\n",
    "    colors = img.reshape(-1, 3)  # Just flatten color image\n",
    "    \n",
    "    foreground_mask = depth_img.reshape(-1) < depth_threshold\n",
    "    pointcloud = points_to_render[foreground_mask]\n",
    "    colors = colors[foreground_mask]\n",
    "    \n",
    "    return img, depth_img, img_width, img_height, intrinsics, pointcloud, colors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moral-upset",
   "metadata": {},
   "source": [
    "# 2. Detect 3D landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "indonesian-movie",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_3d_landmarks(img, depth_img):\n",
    "    landmarks_img, face_pos = detect_landmarks(img, return_face_pos=True)\n",
    "    face_pos = face_pos[0]\n",
    "    \n",
    "    # Interpolate\n",
    "    interpolation_size = 1\n",
    "    rgb_depth_values = [interpolate_around(depth_img, pixel, interpolation_size) for pixel in landmarks_img]\n",
    "    \n",
    "    landmark_points_3d = backproject_points(intrinsics, rgb_depth_values, landmarks_img)\n",
    "    landmark_points_3d_render = np.array(landmark_points_3d)\n",
    "    landmark_points_3d_render[:,2] = -landmark_points_3d_render[:,2]  # Invert z-coordinate for easier rendering (landmarks will be right in front of camera)if isinstance(loader, IPhoneDataLoader):\n",
    "    landmark_points_3d_render *= 1000  # meter to millimeter\n",
    "    \n",
    "    # It can happen that depth information is bad and back-projected landmark points are far away from the other. These should be ignored\n",
    "    landmark_points_3d_median = geometric_median(landmark_points_3d_render)\n",
    "    distances_from_median = np.linalg.norm(landmark_points_3d_render - landmark_points_3d_median, axis=1)\n",
    "    threshold_landmark_deviation = 500  \n",
    "    valid_landmark_points_3d = np.where((np.array(rgb_depth_values) != 0) & (distances_from_median < threshold_landmark_deviation))[0]\n",
    "    \n",
    "    return face_pos, valid_landmark_points_3d, landmark_points_3d_render"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fewer-click",
   "metadata": {},
   "source": [
    "## 2.1 Restrict Pointcloud to Facial Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "southeast-footage",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_facial_points(face_pos, depth_img):\n",
    "    face_depth_values = []\n",
    "    face_pixels = []\n",
    "    interpolation_size = 1\n",
    "    \n",
    "    for x in range(face_pos.left(), face_pos.right() + 1):\n",
    "        for y in range(face_pos.top(), face_pos.bottom() + 1):\n",
    "            pixel = [x, y]\n",
    "            face_depth_value = interpolate_around(depth_img, pixel, interpolation_size)\n",
    "            if face_depth_value > 0:\n",
    "                face_depth_values.append(face_depth_value)\n",
    "                face_pixels.append(pixel)\n",
    "                \n",
    "    face_pointcloud = backproject_points(intrinsics, face_depth_values, face_pixels)\n",
    "    face_pointcloud[:, 2] = -face_pointcloud[:, 2]\n",
    "    face_pointcloud_colors = np.array([img[y, x] for x, y in face_pixels])\n",
    "    face_pointcloud *= 1000  # Meters to Millimeters\n",
    "    \n",
    "    body_depth_values = []\n",
    "    body_pixels = []\n",
    "    for x in range(img_width):\n",
    "        for y in range(img_height):\n",
    "            if (x < face_pos.left() or x > face_pos.right()) or (y < face_pos.top() or y > face_pos.bottom()):\n",
    "                pixel = [x, y]\n",
    "                body_depth_value = interpolate_around(depth_img, pixel, interpolation_size)\n",
    "                if body_depth_value > 0:\n",
    "                    body_depth_values.append(body_depth_value)\n",
    "                    body_pixels.append(pixel)\n",
    "                    \n",
    "    body_pointcloud = backproject_points(intrinsics, body_depth_values, body_pixels)\n",
    "    body_pointcloud[:, 2] = -body_pointcloud[:, 2]\n",
    "    body_pointcloud_colors = np.array([img[y, x] for x, y in body_pixels])\n",
    "    body_pointcloud *= 1000  # Meters to Millimetersz\n",
    "    \n",
    "    return face_pointcloud, body_pointcloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "historical-penguin",
   "metadata": {},
   "source": [
    "# 3. ICP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "competent-vegetable",
   "metadata": {},
   "source": [
    "## 3.1 Sparse Recontruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "appointed-silicon",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_params_shape_sparse = 3 # 20\n",
    "n_params_expression_sparse = 3 # 10\n",
    "weight_shape_params_sparse = 100 # 10000\n",
    "weight_expression_params_sparse = 100 # 1000\n",
    "l2_regularization_sparse = 10000  # regularizes only face model parameters\n",
    "rotation_mode = 'quaternion'\n",
    "\n",
    "sparse_optimizer = BFMOptimization(bfm, \n",
    "                               n_params_shape=n_params_shape_sparse,\n",
    "                               n_params_expression=n_params_expression_sparse, \n",
    "                               weight_shape_params=weight_shape_params_sparse, \n",
    "                               weight_expression_params=weight_expression_params_sparse,\n",
    "                               rotation_mode='lie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "educated-moore",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_recon(landmark_points_3d_render, initial_params):\n",
    "    initial_camera_pose = np.eye(4) # position camera just in front of face\n",
    "\n",
    "    if sparse_optimizer.rotation_mode == 'lie':\n",
    "        theta = 0.0001\n",
    "        initial_camera_pose[:3, :3] = np.array([[1, 0, 0], [0, cos(theta), -sin(theta)], [0, sin(theta), cos(theta)]])\n",
    "        assert abs(det(initial_camera_pose) - 1.0) < 0.00001 \n",
    "\n",
    "    if initial_params == None:\n",
    "        initial_params = sparse_optimizer.create_parameters(\n",
    "            [0 for _ in range(n_shape_coefficients)],\n",
    "            [0 for _ in range(n_expression_coefficients)],\n",
    "            initial_camera_pose\n",
    "        )\n",
    "    \n",
    "    sparse_loss = sparse_optimizer.create_sparse_loss_3d(bfm_landmark_indices[valid_landmark_points_3d], landmark_points_3d_render[valid_landmark_points_3d], regularization_strength=l2_regularization_sparse)\n",
    "    sparse_context = sparse_optimizer.create_optimization_context(sparse_loss, initial_params)\n",
    "    result = sparse_context.run_optimization(sparse_loss, initial_params)\n",
    "    \n",
    "    return sparse_context.create_parameters_from_theta(result.x)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handled-joint",
   "metadata": {},
   "source": [
    "## 3.2 Dense Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "perfect-constitution",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_params_shape_dense = 20 # 20\n",
    "n_params_expression_dense = 20 # 10\n",
    "weight_shape_params_dense = 100 # 10000\n",
    "weight_expression_params_dense = 100 # 1000\n",
    "rotation_mode = 'lie'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "altered-creek",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_optimizer = BFMOptimization(bfm, \n",
    "                               n_params_shape=n_params_shape_dense,\n",
    "                               n_params_expression=n_params_expression_dense, \n",
    "                               weight_shape_params=weight_shape_params_dense, \n",
    "                               weight_expression_params=weight_expression_params_dense,\n",
    "                               rotation_mode=rotation_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "recent-palestine",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_recon(face_pointcloud, params_sparse, skip_shape):\n",
    "    nn_mode = NearestNeighborMode.FACE_VERTICES # FACE_VERTICES: every face vertex will be assigned its nearest neighbor in pointcloud\n",
    "                                            # POINTCLOUD: every point in pointcloud will be assigned its nearest neighbor in face model\n",
    "    if skip_shape: \n",
    "        n_params_shape_dense=0\n",
    "    else:\n",
    "        n_params_shape_dense=20\n",
    "    dense_optimizer = BFMOptimization(bfm, \n",
    "                               n_params_shape=n_params_shape_dense,\n",
    "                               n_params_expression=n_params_expression_dense, \n",
    "                               weight_shape_params=weight_shape_params_dense, \n",
    "                               weight_expression_params=weight_expression_params_dense,\n",
    "                               rotation_mode=rotation_mode,)\n",
    "    \n",
    "    distance_type = DistanceType.POINT_TO_POINT\n",
    "    icp_iterations = 2\n",
    "    optimization_steps_per_iteration = 20\n",
    "    l2_regularization_dense = 1000 # 100\n",
    "    \n",
    "    params, distances, _ = run_icp(dense_optimizer, \n",
    "                               face_pointcloud,\n",
    "                               bfm, \n",
    "                               params_sparse.with_new_manager(dense_optimizer), \n",
    "                               max_iterations=icp_iterations, \n",
    "                               nearest_neighbor_mode=nn_mode, \n",
    "                               distance_type=distance_type,\n",
    "                               max_nfev=optimization_steps_per_iteration,\n",
    "                               l2_regularization=l2_regularization_dense)\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addressed-herald",
   "metadata": {},
   "source": [
    "# 4. Render Face Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "armed-termination",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_scene(params_render, intrinsics, img_width, img_height, pointcloud, colors, show_pointcloud=True, show_mask=True, show_pointcloud_face=False, cut_around_face=4):\n",
    "    \n",
    "    face_mesh = bfm.draw_sample(\n",
    "        shape_coefficients=params_render.shape_coefficients, \n",
    "        expression_coefficients=params_render.expression_coefficients, \n",
    "        color_coefficients=params_render.color_coefficients)\n",
    "    \n",
    "    bfm_vertices = params_render.camera_pose @ add_column(face_mesh.vertices, 1).T\n",
    "    distances, indices = nearest_neighbors(pointcloud, bfm_vertices[:3, :].T)\n",
    "    pointcloud_mask = distances > cut_around_face\n",
    "    \n",
    "    perspective_camera = get_perspective_camera(intrinsics, img_width, img_height)\n",
    "    scene = setup_standard_scene(perspective_camera)\n",
    "    if show_pointcloud and show_pointcloud_face:\n",
    "        scene.add(pyrender.Mesh.from_points(pointcloud[pointcloud_mask], colors=colors[pointcloud_mask]), pose=initial_camera_pose)\n",
    "    if show_mask:\n",
    "        scene.add(pyrender.Mesh.from_trimesh(bfm.convert_to_trimesh(face_mesh)), pose=params_render.camera_pose)\n",
    "    if not show_pointcloud and show_pointcloud_face:\n",
    "        scene.add(pyrender.Mesh.from_points(face_pointcloud, colors=face_pointcloud_colors), pose=initial_camera_pose)\n",
    "    if show_pointcloud and not show_pointcloud_face:\n",
    "        scene.add(pyrender.Mesh.from_points(body_pointcloud, colors=body_pointcloud_colors), pose=initial_camera_pose)\n",
    "    return scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "arctic-october",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_img(scene, width, height):\n",
    "    r = pyrender.OffscreenRenderer(img_width, img_height)\n",
    "    color, depth = r.render(scene)\n",
    "    r.delete()\n",
    "    img_with_mask = np.array(img)\n",
    "    img_with_mask[depth != 0] = color[depth != 0]\n",
    "    return img_with_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "julian-appraisal",
   "metadata": {},
   "source": [
    "# Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "delayed-bottle",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "   Iteration     Total nfev        Cost      Cost reduction    Step norm     Optimality   \n",
      "       0              1         7.1030e+06                                    8.48e+06    \n",
      "       1              2         7.1027e+06      3.50e+02       8.94e-03       8.22e+06    \n",
      "       2              3         7.1020e+06      7.00e+02       1.81e-02       8.46e+06    \n",
      "       3              4         7.1006e+06      1.39e+03       3.60e-02       7.65e+06    \n",
      "       4              5         7.0978e+06      2.80e+03       7.37e-02       7.34e+06    \n",
      "       5              6         7.0922e+06      5.60e+03       1.48e-01       7.62e+06    \n",
      "       6              7         7.0810e+06      1.12e+04       2.91e-01       7.83e+06    \n",
      "       7              8         7.0587e+06      2.23e+04       5.82e-01       7.96e+06    \n",
      "       8              9         7.0141e+06      4.45e+04       1.16e+00       8.10e+06    \n",
      "       9             10         6.9256e+06      8.85e+04       2.32e+00       7.97e+06    \n",
      "      10             11         6.7503e+06      1.75e+05       4.64e+00       7.87e+06    \n",
      "      11             12         6.4089e+06      3.41e+05       9.15e+00       7.91e+06    \n",
      "      12             13         5.7548e+06      6.54e+05       1.87e+01       5.98e+06    \n",
      "      13             14         4.5643e+06      1.19e+06       3.85e+01       6.65e+06    \n",
      "      14             15         2.6495e+06      1.91e+06       7.76e+01       1.63e+06    \n",
      "      15             16         4.9455e+05      2.15e+06       1.67e+02       1.45e+06    \n",
      "      16             17         4.8902e+04      4.46e+05       1.58e+02       5.13e+05    \n",
      "      17             18         1.4542e+04      3.44e+04       3.53e+01       1.55e+05    \n",
      "      18             19         1.1499e+04      3.04e+03       2.45e+01       7.87e+04    \n",
      "      19             20         1.1202e+04      2.97e+02       2.89e+00       2.54e+04    \n",
      "      20             21         1.1174e+04      2.82e+01       5.71e-01       2.90e+04    \n",
      "      21             25         1.1174e+04      2.89e-02       3.40e-03       7.85e+04    \n",
      "      22             26         1.1173e+04      2.16e-01       3.66e-04       1.84e+04    \n",
      "      23             27         1.1173e+04      4.56e-02       2.04e-04       5.52e+04    \n",
      "      24             28         1.1173e+04      6.18e-02       9.76e-05       3.71e+04    \n",
      "      25             29         1.1173e+04      6.29e-02       1.68e-04       2.54e+04    \n",
      "      26             30         1.1173e+04      3.32e-02       2.43e-04       2.80e+04    \n",
      "      27             31         1.1173e+04      2.00e-02       1.63e-04       3.72e+04    \n",
      "      28             32         1.1173e+04      1.68e-03       3.18e-05       1.81e+04    \n",
      "      29             33         1.1173e+04      1.32e-03       1.76e-05       3.38e+04    \n",
      "      30             34         1.1173e+04      1.23e-03       9.18e-06       2.79e+04    \n",
      "      31             35         1.1173e+04      1.38e-03       2.19e-06       1.95e+04    \n",
      "`xtol` termination condition is satisfied.\n",
      "Function evaluations 35, initial cost 7.1030e+06, final cost 1.1173e+04, first-order optimality 1.95e+04.\n",
      "initial key reconstruction..\n",
      "   Iteration     Total nfev        Cost      Cost reduction    Step norm     Optimality   \n",
      "       0              1         7.3028e+05                                    1.62e+07    \n",
      "       1              2         6.1224e+05      1.18e+05       4.14e+00       3.49e+06    \n",
      "       2              3         5.5873e+05      5.35e+04       2.57e+00       2.37e+06    \n",
      "       3              4         5.3426e+05      2.45e+04       1.70e-01       1.73e+06    \n",
      "       4              5         5.1772e+05      1.65e+04       2.67e-01       1.44e+06    \n",
      "       5              6         5.0571e+05      1.20e+04       2.05e-01       1.08e+06    \n",
      "       6              7         4.9725e+05      8.45e+03       1.45e-01       7.16e+05    \n",
      "       7              8         4.9027e+05      6.98e+03       3.34e-01       7.76e+05    \n",
      "       8              9         4.8483e+05      5.44e+03       2.14e-01       9.19e+05    \n",
      "       9             10         4.7900e+05      5.84e+03       3.10e-01       5.89e+05    \n",
      "      10             11         4.7501e+05      3.99e+03       1.75e-01       5.26e+05    \n",
      "      11             12         4.7242e+05      2.59e+03       1.74e-01       8.60e+05    \n",
      "      12             13         4.6937e+05      3.04e+03       2.03e-01       5.45e+05    \n",
      "      13             14         4.6674e+05      2.63e+03       1.89e-01       6.63e+05    \n",
      "      14             15         4.6452e+05      2.23e+03       1.47e-01       9.44e+05    \n",
      "      15             16         4.6205e+05      2.47e+03       1.55e-01       6.31e+05    \n",
      "      16             17         4.6018e+05      1.87e+03       1.36e-01       4.63e+05    \n",
      "      17             18         4.5855e+05      1.63e+03       2.26e-01       6.01e+05    \n",
      "      18             19         4.5717e+05      1.38e+03       1.24e-01       7.60e+05    \n",
      "      19             20         4.5551e+05      1.66e+03       1.10e-01       7.31e+05    \n",
      "The maximum number of function evaluations is exceeded.\n",
      "Function evaluations 20, initial cost 7.3028e+05, final cost 4.5551e+05, first-order optimality 7.31e+05.\n",
      "   Iteration     Total nfev        Cost      Cost reduction    Step norm     Optimality   \n",
      "       0              1         4.1337e+05                                    1.89e+06    \n",
      "       1              2         4.0078e+05      1.26e+04       1.20e+00       2.38e+06    \n",
      "       2              3         3.9638e+05      4.41e+03       1.70e-01       1.35e+06    \n",
      "       3              4         3.9311e+05      3.26e+03       1.97e-01       1.29e+06    \n",
      "       4              5         3.9043e+05      2.68e+03       2.12e-01       8.03e+05    \n",
      "       5              6         3.8859e+05      1.84e+03       1.63e-01       9.20e+05    \n",
      "       6              7         3.8678e+05      1.81e+03       1.40e-01       7.47e+05    \n",
      "       7              8         3.8534e+05      1.44e+03       1.17e-01       6.56e+05    \n",
      "       8              9         3.8395e+05      1.39e+03       1.22e-01       7.07e+05    \n",
      "       9             10         3.8247e+05      1.48e+03       2.67e-01       6.58e+05    \n",
      "      10             11         3.8133e+05      1.14e+03       1.22e-01       6.47e+05    \n",
      "      11             12         3.8029e+05      1.04e+03       1.80e-01       5.71e+05    \n",
      "      12             13         3.7886e+05      1.43e+03       1.89e-01       7.88e+05    \n",
      "      13             14         3.7763e+05      1.23e+03       1.17e-01       7.48e+05    \n",
      "      14             15         3.7676e+05      8.67e+02       1.23e-01       7.89e+05    \n",
      "      15             16         3.7586e+05      9.04e+02       2.65e-01       4.65e+05    \n",
      "      16             17         3.7499e+05      8.75e+02       1.60e-01       7.25e+05    \n",
      "      17             18         3.7429e+05      6.92e+02       2.11e-01       6.91e+05    \n",
      "      18             19         3.7356e+05      7.36e+02       1.20e-01       7.10e+05    \n",
      "      19             20         3.7280e+05      7.57e+02       9.48e-02       4.80e+05    \n",
      "The maximum number of function evaluations is exceeded.\n",
      "Function evaluations 20, initial cost 4.1337e+05, final cost 3.7280e+05, first-order optimality 4.80e+05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|â–         | 1/50 [02:54<2:22:51, 174.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "current_params=None\n",
    "for i in tqdm(range(50)):\n",
    "    print(i)\n",
    "    img, depth_img, img_width, img_height, intrinsics, pointcloud, colors = get_data(i)\n",
    "    face_pos, valid_landmark_points_3d, landmark_points_3d_render = detect_3d_landmarks(img, depth_img)\n",
    "    face_pointcloud, body_pointcloud = extract_facial_points(face_pos, depth_img)\n",
    "    #params_sparse = sparse_recon(landmark_points_3d_render, None)\n",
    "    params_sparse = sparse_recon(landmark_points_3d_render, current_params)\n",
    "    if i == 0:\n",
    "        print(\"initial key reconstruction..\")\n",
    "        current_params = dense_recon(face_pointcloud, params_sparse, False)\n",
    "    else:\n",
    "        current_params = dense_recon(face_pointcloud, params_sparse, True)\n",
    "    \n",
    "    #dense_params = dense_recon(face_pointcloud, params_sparse, False)\n",
    "    \n",
    "    scene = setup_scene(dense_params, intrinsics, img_width, img_height, pointcloud, colors, show_pointcloud=False, show_mask=True)\n",
    "    img = render_img(scene, img_width, img_height) \n",
    "    \n",
    "    img_path = os.path.join(PLOTS_PATH, f'marc_{i:03d}.jpg')\n",
    "    plt.imsave(img_path, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "potential-following",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "democratic-origin",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
